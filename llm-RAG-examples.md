[rag-as-a-service](https://github.com/Shubhamsaboo/awesome-llm-apps/tree/main/rag_tutorials/rag-as-a-service)

[agents-sdk-examples](https://github.com/KodySimpson/agents-sdk)


[rag_pipeline](https://github.com/snsupratim/rag_pdf_chatbot/blob/main/rag_pipeline.py)

[ask-multiple-pdfs-local-llm](https://www.kaggle.com/code/laijaihong/ask-multiple-pdfs-local-llm)

### Chat with Multiple PDFs using Retrieval-Augmented Generation (RAG)¶
This notebook demonstrates how to use Streamlit and LangChain to build a system for chatting with multiple PDFs using Retrieval-Augmented Generation (RAG) and Large Language Models (LLMs). Originally created by Alejandro AO, I’ve adapted it to run on Kaggle using local LLMs instead of relying on an API. This allows you to leverage Kaggle’s resources to experiment with different models via Ollama.
